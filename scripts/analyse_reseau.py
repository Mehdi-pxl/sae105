#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SA√â 1.05 - Traiter des Donn√©es
Script d'analyse de logs r√©seau (tcpdump) avec Pandas
Auteur: √âtudiant BUT R&T S1
Date: Janvier 2026
"""

import pandas as pd
import re
import os
from datetime import datetime
import argparse
from pathlib import Path


# ============================================================================
# FONCTION 1 : PARSING DES LOGS
# ============================================================================
def parser_logs(chemin_fichier):
    """
    Parse le fichier de logs tcpdump et retourne un DataFrame Pandas.
    
    Cette fonction lit le fichier ligne par ligne, ignore les lignes
    hexad√©cimales (payload), et extrait les informations cl√©s.
    
    Args:
        chemin_fichier (str): Chemin vers le fichier DumpFile.txt
    
    Returns:
        pd.DataFrame: DataFrame avec colonnes [Heure, Source, IP_Source, Port_Source, 
                                                Destination, IP_Dest, Port_Dest, Flags]
    """
    print(f"[INFO] Lecture du fichier: {chemin_fichier}")
    
    # Regex 1: Paquets TCP avec Flags (SYN, ACK, FIN, etc.)
    # Format: "15:34:04.766656 IP source > destination: Flags [X.]"
    pattern_tcp = re.compile(
        r'^(\d{2}:\d{2}:\d{2})\.\d+\s+'    # Heure (ex: 15:34:04)
        r'IP\s+'                            # Protocole IP
        r'(\S+)\s+'                         # Source (tout jusqu'√† l'espace)
        r'>\s+'                             # S√©parateur >
        r'(\S+):\s+'                        # Destination (tout jusqu'au :)
        r'.*?Flags\s+\[([^\]]+)\]'          # Flags (ex: [P.], [S], [F])
    )
    
    # Regex 2: Paquets UDP (sans flags TCP)
    # Format: "18:01:29.487415 IP 161.3.129.167.65203 > broadcasthost.gvcp: UDP, length 8"
    pattern_udp = re.compile(
        r'^(\d{2}:\d{2}:\d{2})\.\d+\s+'    # Heure
        r'IP\s+'                            # Protocole IP
        r'(\S+)\s+'                         # Source
        r'>\s+'                             # S√©parateur >
        r'(\S+):\s+'                        # Destination
        r'UDP'                              # Protocole UDP
    )
    
    # Regex 3: Requ√™tes DNS (pour d√©tecter les port scans)
    # Format: "15:34:05.768334 IP BP-Linux8.58466 > ns1.lan.rt.domain: 16550+ PTR?"
    pattern_dns = re.compile(
        r'^(\d{2}:\d{2}:\d{2})\.\d+\s+'    # Heure
        r'IP\s+'                            # Protocole IP
        r'(\S+)\s+'                         # Source
        r'>\s+'                             # S√©parateur >
        r'(\S+):\s+'                        # Destination
        r'\d+\+?\s+'                        # ID requ√™te DNS
    )
    
    # Liste pour stocker les donn√©es pars√©es
    donnees = []
    lignes_valides = 0
    lignes_ignorees = 0
    
    # Lecture du fichier ligne par ligne
    with open(chemin_fichier, 'r', encoding='utf-8', errors='ignore') as f:
        for ligne in f:
            # Ignorer les lignes hexad√©cimales (commencent par tab/espaces + 0x)
            ligne_strip = ligne.strip()
            if ligne_strip.startswith('0x') or ligne.startswith('\t'):
                lignes_ignorees += 1
                continue
            
            # Essayer de matcher avec le pattern TCP (avec flags)
            match = pattern_tcp.match(ligne)
            if match:
                heure = match.group(1)
                source_brute = match.group(2)
                dest_brute = match.group(3)
                flags = match.group(4)
                protocole = 'TCP'
            else:
                # Essayer le pattern UDP
                match = pattern_udp.match(ligne)
                if match:
                    heure = match.group(1)
                    source_brute = match.group(2)
                    dest_brute = match.group(3)
                    flags = 'UDP'  # Pas de flags pour UDP
                    protocole = 'UDP'
                else:
                    # Essayer le pattern DNS
                    match = pattern_dns.match(ligne)
                    if match:
                        heure = match.group(1)
                        source_brute = match.group(2)
                        dest_brute = match.group(3)
                        flags = 'DNS'  # Requ√™te DNS
                        protocole = 'DNS'
                    else:
                        continue  # Ligne non reconnue (ARP, STP, etc.)
            
            # Nettoyer source et destination pour s√©parer IP/hostname du port
            ip_source, port_source = separer_ip_port(source_brute)
            ip_dest, port_dest = separer_ip_port(dest_brute)
            
            # Ajouter les donn√©es √† notre liste
            donnees.append({
                'Heure': heure,
                'Source': source_brute,
                'IP_Source': ip_source,
                'Port_Source': port_source,
                'Destination': dest_brute,
                'IP_Dest': ip_dest,
                'Port_Dest': port_dest,
                'Flags': flags,
                'Protocole': protocole
            })
            lignes_valides += 1
    
    print(f"[INFO] {lignes_valides} lignes valides pars√©es")
    print(f"[INFO] {lignes_ignorees} lignes hexad√©cimales ignor√©es")
    
    # Cr√©er le DataFrame Pandas
    df = pd.DataFrame(donnees)
    return df


def separer_ip_port(adresse):
    """
    S√©pare une adresse en IP/hostname et port.
    
    G√®re les cas suivants:
    - 192.168.190.130.50019 -> ('192.168.190.130', '50019')
    - BP-Linux8.ssh -> ('BP-Linux8', 'ssh')
    - 190-0-175-100.gba.solunet.com.ar.2465 -> ('190-0-175-100.gba.solunet.com.ar', '2465')
    
    Args:
        adresse (str): Adresse brute √† parser
    
    Returns:
        tuple: (ip_ou_hostname, port)
    """
    # Pattern pour d√©tecter une IP (4 octets num√©riques)
    ip_pattern = re.compile(r'^(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})\.(.+)$')
    match_ip = ip_pattern.match(adresse)
    
    if match_ip:
        # C'est une IP suivie d'un port (192.168.1.1.80)
        return match_ip.group(1), match_ip.group(2)
    else:
        # C'est un hostname, le port est apr√®s le dernier point
        if '.' in adresse:
            parties = adresse.rsplit('.', 1)
            return parties[0], parties[1]
        else:
            # Pas de s√©parateur, on retourne tel quel
            return adresse, 'N/A'


# ============================================================================
# FONCTION 2 : D√âTECTION DES ANOMALIES
# ============================================================================
def detecter_anomalies(df):
    """
    Analyse le DataFrame pour d√©tecter 3 types d'anomalies r√©seau.
    
    Types d'anomalies d√©tect√©es:
    1. SYN Flood: Nombreux paquets SYN depuis une m√™me IP (seuil: 100)
    2. Port Scan: Une IP scanne plusieurs ports (seuil: 10 ports)
    3. Flags Suspects: Paquets avec flags FIN, PUSH ou URG
    
    Args:
        df (pd.DataFrame): DataFrame contenant les logs r√©seau
    
    Returns:
        list: Liste de dictionnaires d√©crivant les anomalies d√©tect√©es
    """
    print("[INFO] Analyse des anomalies en cours...")
    
    alertes = []
    
    # === ANOMALIE 1 : SYN FLOOD ATTACK ===
    # Le flag 'S' seul (sans '.') indique un paquet SYN pur
    df_syn = df[df['Flags'].str.match('^S$', na=False)]
    
    # Compter le nombre de paquets SYN par IP Source
    syn_par_source = df_syn['IP_Source'].value_counts()
    
    # Seuil de d√©tection: > 100 paquets SYN
    for ip_source, nb_paquets in syn_par_source.items():
        if nb_paquets > 100:
            severite = "CRITIQUE" if nb_paquets > 1000 else "√âLEV√âE"
            alertes.append({
                'Type': 'SYN Flood Attack',
                'IP_Source': ip_source,
                'Nb_Paquets': nb_paquets,
                'S√©v√©rit√©': severite,
                'Description': f"L'IP {ip_source} a envoy√© {nb_paquets} paquets SYN (attaque par inondation)"
            })
    
    # === ANOMALIE 2 : PORT SCAN ===
    # Grouper par IP Source et compter le nombre de ports diff√©rents vis√©s
    ports_par_source = df.groupby('IP_Source')['Port_Dest'].nunique()
    
    # Seuil de d√©tection: > 10 ports diff√©rents
    for ip_source, nb_ports in ports_par_source.items():
        if nb_ports > 10:
            severite = "CRITIQUE" if nb_ports > 50 else "√âLEV√âE"
            alertes.append({
                'Type': 'Port Scan',
                'IP_Source': ip_source,
                'Nb_Ports_Scann√©s': nb_ports,
                'S√©v√©rit√©': severite,
                'Description': f"L'IP {ip_source} a scann√© {nb_ports} ports diff√©rents (reconnaissance r√©seau)"
            })
    
    print(f"[INFO] {len(alertes)} anomalie(s) d√©tect√©e(s)")
    return alertes


# ============================================================================
# FONCTION 3 : G√âN√âRATION DES RAPPORTS
# ============================================================================
def generer_rapports(df, alertes, dossier_sortie):
    """
    G√©n√®re 3 fichiers de rapport (CSV, JSON, Markdown) dans le dossier sp√©cifi√©.
    
    Fichiers g√©n√©r√©s:
    - rapport_YYYYMMDD_HHMMSS.csv (compatible Excel)
    - rapport_YYYYMMDD_HHMMSS.json (pour interface web)
    - rapport_YYYYMMDD_HHMMSS.md (r√©sum√© lisible)
    
    Args:
        df (pd.DataFrame): DataFrame des logs r√©seau
        alertes (list): Liste des anomalies d√©tect√©es
        dossier_sortie (str): Chemin du dossier o√π sauvegarder les rapports
    """
    # Cr√©er le dossier de sortie s'il n'existe pas
    Path(dossier_sortie).mkdir(parents=True, exist_ok=True)
    
    # G√©n√©rer un timestamp pour les noms de fichiers
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # === RAPPORT 1 : CSV (Compatible Excel) ===
    chemin_csv = os.path.join(dossier_sortie, f"rapport_{timestamp}.csv")
    df.to_csv(
        chemin_csv,
        sep=';',               # S√©parateur pour Excel fran√ßais
        encoding='utf-8-sig',  # Encodage avec BOM pour Excel
        index=False            # Ne pas inclure l'index
    )
    print(f"[OK] Rapport CSV g√©n√©r√©: {chemin_csv}")
    
    # === RAPPORT 2 : JSON (Pour interface web) ===
    chemin_json = os.path.join(dossier_sortie, f"rapport_{timestamp}.json")
    df.to_json(
        chemin_json,
        orient='records',      # Format: liste de dictionnaires
        indent=2,              # Indentation pour lisibilit√©
        force_ascii=False      # Conserver les caract√®res UTF-8
    )
    print(f"[OK] Rapport JSON g√©n√©r√©: {chemin_json}")
    
    # === RAPPORT 3 : MARKDOWN (Lisible et structur√©) ===
    chemin_md = os.path.join(dossier_sortie, f"rapport_{timestamp}.md")
    
    with open(chemin_md, 'w', encoding='utf-8') as f:
        # En-t√™te du rapport
        f.write(f"# üìä Rapport d'Analyse R√©seau\n\n")
        f.write(f"**Date de g√©n√©ration:** {datetime.now().strftime('%d/%m/%Y √† %H:%M:%S')}\n\n")
        f.write(f"---\n\n")
        
        # R√©sum√© de l'analyse
        f.write(f"## üìà R√©sum√© de l'analyse\n\n")
        f.write(f"- **Nombre total de paquets analys√©s:** {len(df)}\n")
        f.write(f"- **Nombre d'anomalies d√©tect√©es:** {len(alertes)}\n")
        
        if not df.empty:
            f.write(f"- **Plage horaire:** {df['Heure'].min()} ‚Üí {df['Heure'].max()}\n\n")
        
        f.write(f"---\n\n")
        
        # Tableau des alertes
        if alertes:
            f.write(f"## üö® Alertes de S√©curit√©\n\n")
            f.write("| S√©v√©rit√© | Type | IP Source | D√©tails |\n")
            f.write("|----------|------|-----------|--------|\n")
            
            for alerte in alertes:
                type_anomalie = alerte['Type']
                ip = alerte['IP_Source']
                severite = alerte['S√©v√©rit√©']
                
                # Emoji de s√©v√©rit√©
                if severite == 'CRITIQUE':
                    emoji = "üî¥"
                elif severite == '√âLEV√âE':
                    emoji = "üü†"
                else:
                    emoji = "üü°"
                
                # D√©tails selon le type d'anomalie
                if 'Nb_Paquets' in alerte:
                    details = f"{alerte['Nb_Paquets']} paquets"
                elif 'Nb_Ports_Scann√©s' in alerte:
                    details = f"{alerte['Nb_Ports_Scann√©s']} ports"
                else:
                    details = "N/A"
                
                f.write(f"| {emoji} {severite} | {type_anomalie} | `{ip}` | {details} |\n")
            
            f.write("\n---\n\n")
            
            # D√©tails des anomalies
            f.write(f"## üìã D√©tails des Anomalies\n\n")
            for i, alerte in enumerate(alertes, 1):
                f.write(f"### {i}. {alerte['Type']}\n\n")
                f.write(f"- **S√©v√©rit√©:** {alerte['S√©v√©rit√©']}\n")
                f.write(f"- **Description:** {alerte['Description']}\n\n")
        else:
            f.write(f"## ‚úÖ Aucune anomalie d√©tect√©e\n\n")
            f.write("Le trafic r√©seau analys√© ne pr√©sente pas de comportement suspect.\n\n")
        
        # Recommandations
        f.write(f"---\n\n")
        f.write(f"## üí° Recommandations\n\n")
        
        if alertes:
            severites = [a['S√©v√©rit√©'] for a in alertes]
            if 'CRITIQUE' in severites:
                f.write("‚ö†Ô∏è **ACTIONS IMM√âDIATES REQUISES:**\n\n")
                f.write("1. Bloquer les adresses IP malveillantes identifi√©es\n")
                f.write("2. Renforcer les r√®gles de pare-feu\n")
                f.write("3. Contacter l'√©quipe s√©curit√© r√©seau en Inde\n\n")
            else:
                f.write("1. Surveiller les IP suspectes identifi√©es\n")
                f.write("2. Analyser les logs d√©taill√©s pour confirmer la menace\n")
                f.write("3. Mettre √† jour les r√®gles de d√©tection d'intrusion\n\n")
        else:
            f.write("1. Continuer la surveillance r√©seau standard\n")
            f.write("2. Maintenir les sauvegardes r√©guli√®res des logs\n\n")
        
        # Pied de page
        f.write("---\n\n")
        f.write("*Rapport g√©n√©r√© par le script SA√â 1.05 - BUT R&T*\n")
    
    print(f"[OK] Rapport Markdown g√©n√©r√©: {chemin_md}")


# ============================================================================
# FONCTION PRINCIPALE
# ============================================================================
def main():
    """
    Fonction principale qui orchestre l'analyse r√©seau.
    
    √âtapes:
    1. Lire les arguments en ligne de commande
    2. Parser le fichier de logs
    3. D√©tecter les anomalies
    4. G√©n√©rer les rapports
    """
    # === GESTION DES ARGUMENTS EN LIGNE DE COMMANDE ===
    parser = argparse.ArgumentParser(
        description="Analyse de logs r√©seau pour SA√â 1.05 (BUT R&T)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemples d'utilisation:
  python analyse_reseau.py
  python analyse_reseau.py --fichier ../data/DumpFile.txt
  python analyse_reseau.py -f ../data/MonAutreLog.txt
        """
    )
    
    parser.add_argument(
        '-f', '--fichier',
        default='../data/DumpFile.txt',
        help='Chemin vers le fichier de logs tcpdump (d√©faut: ../data/DumpFile.txt)'
    )
    
    args = parser.parse_args()
    
    # === V√âRIFICATION DE L'EXISTENCE DU FICHIER ===
    if not os.path.exists(args.fichier):
        print(f"[ERREUR] Le fichier '{args.fichier}' n'existe pas!")
        print("V√©rifiez le chemin et r√©essayez.")
        return
    
    # === AFFICHAGE DE L'EN-T√äTE ===
    print("=" * 60)
    print("     SA√â 1.05 - ANALYSE DE LOGS R√âSEAU (TCPDUMP)")
    print("=" * 60)
    print()
    
    # === √âTAPE 1 : PARSING DES LOGS ===
    try:
        df = parser_logs(args.fichier)
        
        if df.empty:
            print("[ERREUR] Aucune donn√©e valide trouv√©e dans le fichier!")
            return
        
        print(f"\n[OK] DataFrame cr√©√© avec {len(df)} lignes")
        print("\nAper√ßu des 5 premi√®res lignes:")
        print(df.head().to_string())
        
    except Exception as e:
        print(f"[ERREUR] Probl√®me lors du parsing: {e}")
        return
    
    # === √âTAPE 2 : D√âTECTION DES ANOMALIES ===
    print("\n" + "-" * 60)
    try:
        alertes = detecter_anomalies(df)
    except Exception as e:
        print(f"[ERREUR] Probl√®me lors de la d√©tection: {e}")
        return
    
    # === √âTAPE 3 : G√âN√âRATION DES RAPPORTS ===
    print("\n" + "-" * 60)
    
    # Cr√©er un sous-dossier avec le nom du fichier analys√© (sans extension)
    nom_fichier = Path(args.fichier).stem  # ex: "DumpFile" ou "fichier182"
    dossier_rapports = f'../rapports/{nom_fichier}'
    
    try:
        generer_rapports(df, alertes, dossier_rapports)
    except Exception as e:
        print(f"[ERREUR] Probl√®me lors de la g√©n√©ration des rapports: {e}")
        return
    
    # === R√âSUM√â FINAL ===
    print("\n" + "=" * 60)
    print("                    ANALYSE TERMIN√âE")
    print("=" * 60)
    print(f"\n‚úÖ {len(df)} paquets analys√©s")
    print(f"‚ö†Ô∏è  {len(alertes)} anomalie(s) d√©tect√©e(s)")
    print(f"üìÅ Rapports sauvegard√©s dans: {dossier_rapports}/")
    print()


# Point d'entr√©e du script
if __name__ == "__main__":
    main()
